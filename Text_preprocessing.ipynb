{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hxk6YXU7qkG1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3diniA5qruJu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSffW8rFr1gS",
        "outputId": "da74b89d-dc57-46e1-cf4b-0ff3e745b3ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dlZ8ooassIsc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "from nltk import sent_tokenize\n",
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "G6nhWJg4sXTj",
        "outputId": "c972b964-6217-47d9-9509-a21312b2e1eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-79d75056-0e2e-4cc4-9c4b-a006d72586e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79d75056-0e2e-4cc4-9c4b-a006d72586e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79d75056-0e2e-4cc4-9c4b-a006d72586e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79d75056-0e2e-4cc4-9c4b-a006d72586e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-16727ed5-b1fb-41a3-854a-1e808cbfe39c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16727ed5-b1fb-41a3-854a-1e808cbfe39c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-16727ed5-b1fb-41a3-854a-1e808cbfe39c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('Film_IBMDATA_set', nrows=50000)  # Adjust the number of rows as needed\n",
        "df.head()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JKT2Nxn2vJUM"
      },
      "source": [
        "First step is converting all text into lower casing bold text since python is case sensative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "P090BK91upz2",
        "outputId": "571641db-7018-402b-e851-540bdbf523b2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['review'][3].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PRbqesivZHY",
        "outputId": "4ff3e27f-39d7-43ae-87e0-02e57ea15f9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eWtHChePwEl7"
      },
      "source": [
        "**To convert all review into the lower cases.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5DQ7xeuwASt",
        "outputId": "9dd34fbb-1af3-404b-e6ef-ca76593a2e94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        one of the other reviewers has mentioned that ...\n",
              "1        a wonderful little production. <br /><br />the...\n",
              "2        i thought this was a wonderful way to spend ti...\n",
              "3        basically there's a family where a little boy ...\n",
              "4        petter mattei's \"love in the time of money\" is...\n",
              "                               ...                        \n",
              "49995    rififi, directed by jules dassin, is in line w...\n",
              "49996    for anyone who's judged others at first meetin...\n",
              "49997    i couldnt believe how well this kid did on scr...\n",
              "49998    ok, i have been a huge fan of the black for a ...\n",
              "49999    lorenzo lamas stars as some type of cia agent,...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['review'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "a_8FFPFYwfhI"
      },
      "outputs": [],
      "source": [
        "df['review']=df['review'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUzCj_zAwtql",
        "outputId": "40add7aa-4f5e-488f-f2e3-bb025d0ce94e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        one of the other reviewers has mentioned that ...\n",
              "1        a wonderful little production. <br /><br />the...\n",
              "2        i thought this was a wonderful way to spend ti...\n",
              "3        basically there's a family where a little boy ...\n",
              "4        petter mattei's \"love in the time of money\" is...\n",
              "                               ...                        \n",
              "49995    rififi, directed by jules dassin, is in line w...\n",
              "49996    for anyone who's judged others at first meetin...\n",
              "49997    i couldnt believe how well this kid did on scr...\n",
              "49998    ok, i have been a huge fan of the black for a ...\n",
              "49999    lorenzo lamas stars as some type of cia agent,...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['review']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FaqL22RoxGoo"
      },
      "source": [
        "**Remove unimportant information(HTML TAG) use this function to rem0ve html**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WClMeLgVw_eV"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def html_tags(text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub('', text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pttpMjhfzB_7",
        "outputId": "8cc5dc83-265d-41a2-823b-d29dc9d1dcd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              review  \\\n",
            "0  One of the other reviewers has mentioned that ...   \n",
            "1  A wonderful little production. <br /><br />The...   \n",
            "2  I thought this was a wonderful way to spend ti...   \n",
            "3  Basically there's a family where a little boy ...   \n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
            "\n",
            "                                 review_without_html  \n",
            "0  One of the other reviewers has mentioned that ...  \n",
            "1  A wonderful little production. The filming tec...  \n",
            "2  I thought this was a wonderful way to spend ti...  \n",
            "3  Basically there's a family where a little boy ...  \n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  \n"
          ]
        }
      ],
      "source": [
        "df['review_without_html'] = df['review'].apply(html_tags)\n",
        "print(df[['review', 'review_without_html']].head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tKdtaVzs1M-E"
      },
      "source": [
        "**Remove URLS for example whatsapp data or chat or wikipedia text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNJ-ZvCRz0CI",
        "outputId": "e3c4593d-5d48-4332-901f-0403f5ebb0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original text: Check out my website at https://www.example.com. For more information, visit http://anotherexample.com.\n",
            "Text without URLs: Check out my website at  For more information, visit \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub('', text)\n",
        "text_with_urls = \"Check out my website at https://www.example.com. For more information, visit http://anotherexample.com.\"\n",
        "text_without_urls = remove_urls(text_with_urls)\n",
        "\n",
        "print(\"Original text:\", text_with_urls)\n",
        "print(\"Text without URLs:\", text_without_urls)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B72_uRWo2R3X"
      },
      "source": [
        "**Remove Punctuations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAUFNhVO2Djz",
        "outputId": "a263e771-8db4-401e-b3a1-0884a7621920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import time\n",
        "\n",
        "\n",
        "punctuation_chars = string.punctuation\n",
        "print(punctuation_chars)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "jWhOt4D-4-JS"
      },
      "outputs": [],
      "source": [
        "exclude=string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZh6toZu5EI3",
        "outputId": "0af22fbc-e621-45ea-8cb5-20a5fe0d134a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original text: Hello, world! This is an example text with punctuation.\n",
            "Text without punctuation: Hello world This is an example text with punctuation\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def punctuation_chars(text, exclude=None):\n",
        "    if exclude is None:\n",
        "        exclude = string.punctuation\n",
        "\n",
        "    for char in exclude:\n",
        "        text = text.replace(char, '')\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "text_with_punctuation = \"Hello, world! This is an example text with punctuation.\"\n",
        "text_without_punctuation = punctuation_chars(text_with_punctuation)\n",
        "\n",
        "print(\"Original text:\", text_with_punctuation)\n",
        "print(\"Text without punctuation:\", text_without_punctuation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzi7Ites6SHe",
        "outputId": "a714b960-3b03-4066-ef4c-075f93406366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<function punctuation_chars at 0x798787a5dd80>\n",
            "0.00015306472778320312\n"
          ]
        }
      ],
      "source": [
        "start=time.time()\n",
        "print(punctuation_chars)\n",
        "time1=time.time()-start\n",
        "print(time1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu04ITm96wxM"
      },
      "source": [
        "**This is too slow for the fast processing use following functions to remove function.....**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "4P-nFMuu68JU"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ultDO4P070Vb",
        "outputId": "80f3025b-8695-4ed4-bf02-b2be437242ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<function punctuation_chars at 0x798787a5dd80>\n",
            "0.0017235279083251953\n"
          ]
        }
      ],
      "source": [
        "start=time.time()\n",
        "print(punctuation_chars)\n",
        "time2=time.time()-start\n",
        "print(time2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM8ZpSOH756u",
        "outputId": "b5394dbc-31d7-4c1c-d6de-d8a677187810"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        One of the other reviewers has mentioned that ...\n",
              "1        A wonderful little production br br The filmin...\n",
              "2        I thought this was a wonderful way to spend ti...\n",
              "3        Basically theres a family where a little boy J...\n",
              "4        Petter Matteis Love in the Time of Money is a ...\n",
              "                               ...                        \n",
              "49995    Rififi directed by Jules Dassin is in line wit...\n",
              "49996    For anyone whos judged others at first meeting...\n",
              "49997    I couldnt believe how well this kid did on scr...\n",
              "49998    OK I have been a huge fan of the Black for a l...\n",
              "49999    Lorenzo Lamas stars as some type of CIA agent ...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['review'].apply(remove_punctuation)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtxT7bRP83_G"
      },
      "source": [
        "**Chat word treatment or Salang word treatment** for this you have to used dictionary........... Use following function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7Zm1Ddo8jMp",
        "outputId": "0b6851eb-eb38-4a4d-96b1-c0ad4b68ed5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original text: R U coming or not? BRB, I'm L8.\n",
            "Converted text: are you coming or not? BRB, I'm L8.\n"
          ]
        }
      ],
      "source": [
        "def chat_conversation(text):\n",
        "    new_text = []\n",
        "    chat_words = {\"R\": \"are\", \"U\": \"you\", \"L8\": \"late\", \"BRB\": \"be right back\"}\n",
        "\n",
        "    for word in text.split():\n",
        "        if word.upper() in chat_words:\n",
        "            new_text.append(chat_words[word.upper()])\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "\n",
        "    return ' '.join(new_text)\n",
        "\n",
        "# Example usage:\n",
        "input_text = \"R U coming or not? BRB, I'm L8.\"\n",
        "output_text = chat_conversation(input_text)\n",
        "\n",
        "print(\"Original text:\", input_text)\n",
        "print(\"Converted text:\", output_text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vXNrUjGD-13m"
      },
      "source": [
        "**Spelling correction for text preprocessing.It handel the common types of general mistake....**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztc2XpIH-nfm",
        "outputId": "0b5b184b-5cc1-492d-e15e-7ba6e1a67f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: Thee quick brown fox jumpd ovver the lazy dog.\n",
            "Corrected Text: Thee quick brown fox jumped over the lazy dog.\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "text_with_mistakes = \"Thee quick brown fox jumpd ovver the lazy dog.\"\n",
        "blob = TextBlob(text_with_mistakes)\n",
        "corrected_text = blob.correct()\n",
        "\n",
        "print(\"Original Text:\", text_with_mistakes)\n",
        "print(\"Corrected Text:\", corrected_text)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN-lx6GUAMRL"
      },
      "source": [
        "**Remove the stop words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5owIL-J5APwh",
        "outputId": "a3d0d229-4464-40f2-a037-3e39eedf0e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'yourself', 'him', 'do', 'under', 'those', 'don', 'mightn', \"mustn't\", 'during', 'hers', 'her', 'should', 'won', 'why', 'haven', 'am', 'what', 'these', 'wouldn', \"she's\", 'hasn', 'against', \"it's\", \"you'd\", 'own', \"weren't\", 'aren', \"aren't\", 'about', 'our', 'this', 'does', 'no', 'just', 'them', 'are', 've', 'above', 'doing', 'd', 'themselves', \"won't\", 'his', 'they', 'my', 'we', 'how', 's', 'myself', 'same', 'between', 'very', 'below', 'll', 'shan', 'the', 'hadn', 'weren', 'isn', 'having', 'a', 'into', 'further', 'y', \"wasn't\", 'being', 'up', \"didn't\", 'until', 'other', 'that', 'out', 'itself', 'needn', 'on', 'shouldn', 'then', 'down', 'more', 'at', 'where', 'have', 'and', 'than', 'of', 'when', 'himself', 're', \"needn't\", 'in', 'doesn', 'while', 'nor', \"you're\", \"that'll\", 'ourselves', 'with', \"you'll\", 'was', 'were', 'be', 'over', 'herself', 'ours', \"mightn't\", \"shan't\", \"hasn't\", \"hadn't\", 'mustn', 'yours', 'which', 'both', \"wouldn't\", 'its', 'there', \"haven't\", 'can', 'their', 'too', 'each', \"don't\", 'theirs', \"doesn't\", 'again', 'couldn', 'wasn', 'most', 'who', 'because', 'will', 'm', 'or', 'didn', 'is', 'by', 'ain', \"should've\", 'off', 't', 'he', 'to', 'few', \"isn't\", 'ma', 'whom', 'but', 'here', 'now', 'from', 'an', 'if', 'o', 'been', 'so', 'as', 'through', 'not', 'had', 'has', 'it', 'yourselves', 'for', 'all', 'did', 'any', 'only', 'once', 'your', 'before', \"shouldn't\", 'after', 'i', 'you', \"you've\", \"couldn't\", 'she', 'such', 'me', 'some'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cQVQnTsBAi6",
        "outputId": "71edcfbd-3236-4928-b972-e6add12ad9ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: This is an example sentence with some stopwords.\n",
            "Text without Stopwords: example sentence stopwords .\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "# This function remove the stopwords\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    filtered_text = ' '.join(filtered_words)\n",
        "\n",
        "    return filtered_text\n",
        "\n",
        "# Example usage:\n",
        "input_text = \"This is an example sentence with some stopwords.\"\n",
        "output_text = remove_stopwords(input_text)\n",
        "\n",
        "print(\"Original Text:\", input_text)\n",
        "print(\"Text without Stopwords:\", output_text)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YDNp_LZ1CXTD"
      },
      "source": [
        "**Emoji Handeling Function.....** use the demojize function....."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3IiekirCmhC",
        "outputId": "a756102a-1a1f-44f7-ad6b-4b551cf20891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.10.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iZby-5tCczt",
        "outputId": "9500c37e-d608-4323-d644-040a74fd53b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: Hello! ðŸ˜Š How are you today? ðŸŒŸ\n",
            "Text without Emojis: Hello! smiling_face_with_smiling_eyes How are you today? glowing_star\n"
          ]
        }
      ],
      "source": [
        "import emoji\n",
        "\n",
        "def remove_emojis(text):\n",
        "    cleaned_text = emoji.demojize(text)\n",
        "    cleaned_text = cleaned_text.replace(\":\", \"\")\n",
        "    return cleaned_text\n",
        "\n",
        "# Example usage:\n",
        "text_with_emojis = \"Hello! ðŸ˜Š How are you today? ðŸŒŸ\"\n",
        "text_without_emojis = remove_emojis(text_with_emojis)\n",
        "\n",
        "print(\"Original Text:\", text_with_emojis)\n",
        "print(\"Text without Emojis:\", text_without_emojis)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Yw5WGGDHgw"
      },
      "source": [
        "**Tokanization very important step of NLP**\n",
        "why tokanization is so important? It is helps to filter the number of Uniques words. while doing Tokenization alot challenges happen. for example $20 , New-york.....\n",
        "Tokenization faces challenges such as handling word boundary ambiguity, deciding punctuation inclusion, and addressing complexities in abbreviations and acronyms. Multilingual variations, noisy text, sentence boundary identification, and customization for specific tasks like information extraction further contribute to the nuanced nature of tokenization challenges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ9nlne1DGrV",
        "outputId": "4bcf73e9-617f-4102-c80b-726892d69667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: Tokenization using split function is a basic approach.\n",
            "Tokens using split: ['Tokenization', 'using', 'split', 'function', 'is', 'a', 'basic', 'approach.']\n"
          ]
        }
      ],
      "source": [
        "#1 use split function\n",
        "def tokenize_with_split(text):\n",
        "    # Tokenize using split function\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Example usage:\n",
        "example_text = \"Tokenization using split function is a basic approach.\"\n",
        "tokens = tokenize_with_split(example_text)\n",
        "\n",
        "print(\"Original Text:\", example_text)\n",
        "print(\"Tokens using split:\", tokens)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cEjB5Yk-FjEy"
      },
      "source": [
        "**Handalin in tokenization**\n",
        " If you're experiencing issues with using the split function in Natural Language Processing (NLP), it's important to understand that the basic split function in Python is limited and may not handle certain tokenization challenges effectively, such as punctuation, contractions, or different languages.\n",
        " In NLP, more advanced tokenization methods are often preferred. The nltk library provides a more powerful word_tokenize function that can handle various tokenization challenges  **NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK2F5yoqFiNU",
        "outputId": "2e4abe34-4c3f-436d-8b83-430d2673f72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: Advanced NLP tokenization requires specialized tools?But I am going to new-york.\n",
            "Tokens using nltk: ['Advanced', 'NLP', 'tokenization', 'requires', 'specialized', 'tools', '?', 'But', 'I', 'am', 'going', 'to', 'new-york', '.']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "def tokenize_with_nltk(text):\n",
        "    # Tokenize using nltk's word_tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "# Example usage:\n",
        "example_text = \"Advanced NLP tokenization requires specialized tools?But I am going to new-york.\"\n",
        "tokens_nltk = tokenize_with_nltk(example_text)\n",
        "\n",
        "print(\"Original Text:\", example_text)\n",
        "print(\"Tokens using nltk:\", tokens_nltk)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OW69oyryHCEQ"
      },
      "source": [
        "**Spacy**\n",
        "Spacy is a popular library for natural language processing (NLP) in Python, and it provides robust tools for tokenization and various other NLP tasks. Here's an example of how to use Spacy for tokenization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8Eeo4zTHMYr",
        "outputId": "f3f3fc79-6bb9-468a-ad8e-1b5d196bae9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: I am Ph.D student.\n",
            "Tokens using Spacy: ['I', 'am', 'Ph', '.', 'D', 'student', '.']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def tokenize_with_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text for token in doc]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Example usage:\n",
        "example_text = \"I am Ph.D student.\"\n",
        "tokens_spacy = tokenize_with_spacy(example_text)\n",
        "\n",
        "print(\"Original Text:\", example_text)\n",
        "print(\"Tokens using Spacy:\", tokens_spacy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sm10-5wQIMRd"
      },
      "source": [
        "**Stemming**\n",
        "Stemming is a text normalization process in natural language processing that involves reducing words to their root or base form. It helps in simplifying words to their common base, which can be useful for tasks like information retrieval and text analysis. Here's an example using the NLTK library for stemming:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQmOUj8FIZzU",
        "outputId": "fe34424c-9018-46da-cd73-16f31bb17adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: I am very interested in the NPL algorithm and i want to be very successful data scientist and ML engineer.\n",
            "Stemmed Text: i am veri interest in the npl algorithm and i want to be veri success data scientist and ml engin .\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "def stem_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
        "    stemmed_text = ' '.join(stemmed_words)\n",
        "\n",
        "    return stemmed_text\n",
        "\n",
        "# Example usage:\n",
        "original_text = \"I am very interested in the NPL algorithm and i want to be very successful data scientist and ML engineer.\"\n",
        "stemmed_text = stem_text(original_text)\n",
        "\n",
        "print(\"Original Text:\", original_text)\n",
        "print(\"Stemmed Text:\", stemmed_text)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wd3_4VonJfsF"
      },
      "source": [
        "**Snow ball** The Snowball Stemmer is another stemming algorithm, specifically designed to be more aggressive and language-specific than the Porter Stemmer. Here's an example using the Snowball Stemmer in NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGNMUJwAJVaE",
        "outputId": "33348839-7fc9-4f16-dc53-f17791ca469e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: Stemming with Snowball is more aggressive and language-specific.\n",
            "Snowball Stemmed Text: stem with snowbal is more aggress and language-specif .\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Initialize the Snowball Stemmer for English\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "def snowball_stem_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    stemmed_words = [snowball_stemmer.stem(word) for word in words]\n",
        "    stemmed_text = ' '.join(stemmed_words)\n",
        "    return stemmed_text\n",
        "\n",
        "# Example usage:\n",
        "original_text = \"Stemming with Snowball is more aggressive and language-specific.\"\n",
        "stemmed_text_snowball = snowball_stem_text(original_text)\n",
        "\n",
        "print(\"Original Text:\", original_text)\n",
        "print(\"Snowball Stemmed Text:\", stemmed_text_snowball)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hdPi0RzKKGZR"
      },
      "source": [
        "**Lemmatization** Lemmatization is a text normalization process in natural language processing that involves reducing words to their base or dictionary form (lemma). Unlike stemming, lemmatization ensures that the resulting word is a valid word by considering its context and part of speech. Here's an example using the NLTK library for lemmatization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiH59QGDJefz",
        "outputId": "425471eb-069d-4995-d047-8839b498494f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: I am going to University and talk with my professor for my ph.d research.\n",
            "Lemmatized Text: I am going to University and talk with my professor for my ph.d research .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download the WordNet resource\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    lemmatized_text = ' '.join(lemmatized_words)\n",
        "\n",
        "    return lemmatized_text\n",
        "\n",
        "# Example usage:\n",
        "original_text = \"I am going to University and talk with my professor for my ph.d research.\"\n",
        "lemmatized_text = lemmatize_text(original_text)\n",
        "\n",
        "print(\"Original Text:\", original_text)\n",
        "print(\"Lemmatized Text:\", lemmatized_text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
